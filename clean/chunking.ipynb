{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11125797,"sourceType":"datasetVersion","datasetId":6938443},{"sourceId":11126749,"sourceType":"datasetVersion","datasetId":6939144}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import BartTokenizerFast\nimport os\nimport json\nimport regex as re\nimport polars as pl\nimport torch\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-22T17:06:18.805111Z","iopub.execute_input":"2025-03-22T17:06:18.805417Z","iopub.status.idle":"2025-03-22T17:06:24.950350Z","shell.execute_reply.started":"2025-03-22T17:06:18.805388Z","shell.execute_reply":"2025-03-22T17:06:24.949246Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"tokenizer = BartTokenizerFast.from_pretrained(\"/kaggle/input/nepbart-tokenizer/nepbart_tokenizer\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T17:06:24.951630Z","iopub.execute_input":"2025-03-22T17:06:24.952112Z","iopub.status.idle":"2025-03-22T17:06:25.118573Z","shell.execute_reply.started":"2025-03-22T17:06:24.952071Z","shell.execute_reply":"2025-03-22T17:06:25.117559Z"}},"outputs":[{"name":"stderr","text":"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \nThe tokenizer class you load from this checkpoint is 'PreTrainedTokenizerFast'. \nThe class this function is called from is 'BartTokenizerFast'.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"random.choice([1, 2, 3])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T17:06:25.120472Z","iopub.execute_input":"2025-03-22T17:06:25.120783Z","iopub.status.idle":"2025-03-22T17:06:25.126739Z","shell.execute_reply.started":"2025-03-22T17:06:25.120734Z","shell.execute_reply":"2025-03-22T17:06:25.125951Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"def token_infilling(\n    tokenized_sequence: torch.Tensor,\n    mask_token_id: int,\n    mask_probability: float = 0.15,\n    list_special_tokens: list = [],\n) -> str:\n    # print(len(tokenized_sequence))\n    # print(tokenized_sequence)\n    # if len(tokenied_sequence) <= 10:\n    span_length = int(torch.poisson(torch.tensor([3.0])))\n    perturbed_ids = torch.empty(0, dtype=torch.long)\n    ## If span_length is found to be 0, make it 1, 2, or 3 randomly\n    if span_length == 0:\n        span_length = random.choice([1, 2, 3])\n    # print(span_length)\n    for i in range(0, len(tokenized_sequence), span_length):\n        mask_pl = torch.rand(1)\n        # print(mask_pl)\n        if mask_pl < mask_probability:\n            # check if the span does not contain special tokens\n            # print([token in list_special_tokens for token in tokenized_sequence[i : i + span_length]])\n            if not any([token in list_special_tokens for token in tokenized_sequence[i : i + span_length]]):\n                perturbed_ids = torch.cat(\n                    (perturbed_ids, torch.tensor([mask_token_id], dtype=torch.long))\n                )\n        else:\n            perturbed_ids = torch.cat(\n                (perturbed_ids, tokenized_sequence[i : i + span_length])\n            )\n    if mask_token_id not in perturbed_ids:\n        return token_infilling(\n            tokenized_sequence,\n            mask_token_id,\n            mask_probability,\n            list_special_tokens,\n        )\n                \n    # print(len(perturbed_ids))\n    return perturbed_ids\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T17:06:25.128535Z","iopub.execute_input":"2025-03-22T17:06:25.128899Z","iopub.status.idle":"2025-03-22T17:06:25.146413Z","shell.execute_reply.started":"2025-03-22T17:06:25.128872Z","shell.execute_reply":"2025-03-22T17:06:25.145281Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# tokenizer(\"महायज्ञ गर्न दलित परिवारको उठीबास लगाएको घटनामा संवेदनशील भएर कार्य नगरेको भन्दै गृह महायज्ञ गर्न दलित परिवारको उठीबास लगाएको घटनामा  भएर कार्य नगरेको भन्दै गृह महायज्ञ गर्न दलित परिवारको उठीबास लगाएको घटनामा संवेदनशील भएर कार्य नगरेको भन्दै गृह महायज्ञ गर्न दलित परिवारको उठीबास लगाएको\", return_tensors='pt', max_length=100, padding='max_length')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T17:06:25.147391Z","iopub.execute_input":"2025-03-22T17:06:25.147679Z","iopub.status.idle":"2025-03-22T17:06:25.168040Z","shell.execute_reply.started":"2025-03-22T17:06:25.147646Z","shell.execute_reply":"2025-03-22T17:06:25.166963Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# token_infilling(tokenizer(\"महायज्ञ गर्न दलित परिवारको उठीबास लगाएको घटनामा संवेदनशील भएर कार्य नगरेको भन्दै गृह महायज्ञ गर्न दलित परिवारको उठीबास लगाएको घटनामा  भएर कार्य नगरेको भन्दै गृह महायज्ञ गर्न दलित परिवारको उठीबास लगाएको घटनामा संवेदनशील भएर कार्य नगरेको भन्दै गृह महायज्ञ गर्न दलित परिवारको उठीबास लगाएको\", return_tensors='pt')['input_ids'][0], tokenizer.mask_token_id, list_special_tokens=tokenizer.all_special_ids)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T17:06:25.169018Z","iopub.execute_input":"2025-03-22T17:06:25.169336Z","iopub.status.idle":"2025-03-22T17:06:25.193503Z","shell.execute_reply.started":"2025-03-22T17:06:25.169306Z","shell.execute_reply":"2025-03-22T17:06:25.192524Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train = pl.read_parquet('/kaggle/input/nepbart-llm-dataset/nepbart_dataset/nepbart_test.parquet')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T17:06:25.194492Z","iopub.execute_input":"2025-03-22T17:06:25.194788Z","iopub.status.idle":"2025-03-22T17:06:30.304180Z","shell.execute_reply.started":"2025-03-22T17:06:25.194736Z","shell.execute_reply":"2025-03-22T17:06:30.303339Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"SEQUENCE_LENGTH = 768","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T17:06:30.305250Z","iopub.execute_input":"2025-03-22T17:06:30.305602Z","iopub.status.idle":"2025-03-22T17:06:30.309617Z","shell.execute_reply.started":"2025-03-22T17:06:30.305564Z","shell.execute_reply":"2025-03-22T17:06:30.308636Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"len(train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T17:06:30.312359Z","iopub.execute_input":"2025-03-22T17:06:30.312637Z","iopub.status.idle":"2025-03-22T17:06:30.331373Z","shell.execute_reply.started":"2025-03-22T17:06:30.312611Z","shell.execute_reply":"2025-03-22T17:06:30.330397Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"218326"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"labels = []\nfor row in train.iter_rows(named=True):\n    tokenized = tokenizer(row['text'], return_tensors='pt')['input_ids'][0]\n\n    for i in range(0, len(tokenized), SEQUENCE_LENGTH - 2):\n        if len(tokenized[i:i+SEQUENCE_LENGTH - 2]) < 10:\n            continue\n        \n        labels.append(tokenizer.decode(tokenized[i:i+SEQUENCE_LENGTH - 2], skip_special_tokens=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-22T17:06:30.332695Z","iopub.execute_input":"2025-03-22T17:06:30.333015Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(labels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_df = pl.DataFrame({\n    'text': labels\n})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(final_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"final_df.write_parquet('/kaggle/working/nepbart_chunked_test.parquet')","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}